{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn in /home/fabricio/.pyenv/versions/3.10.0/lib/python3.10/site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in /home/fabricio/.pyenv/versions/3.10.0/lib/python3.10/site-packages (from sklearn) (1.0.2)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/fabricio/.pyenv/versions/3.10.0/lib/python3.10/site-packages (from scikit-learn->sklearn) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/fabricio/.pyenv/versions/3.10.0/lib/python3.10/site-packages (from scikit-learn->sklearn) (3.1.0)\n",
      "Requirement already satisfied: numpy>=1.14.6 in /home/fabricio/.pyenv/versions/3.10.0/lib/python3.10/site-packages (from scikit-learn->sklearn) (1.22.3)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /home/fabricio/.pyenv/versions/3.10.0/lib/python3.10/site-packages (from scikit-learn->sklearn) (1.8.0)\n",
      "Requirement already satisfied: matplotlib in /home/fabricio/.pyenv/versions/3.10.0/lib/python3.10/site-packages (3.5.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/fabricio/.pyenv/versions/3.10.0/lib/python3.10/site-packages (from matplotlib) (1.4.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/fabricio/.pyenv/versions/3.10.0/lib/python3.10/site-packages (from matplotlib) (1.22.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/fabricio/.pyenv/versions/3.10.0/lib/python3.10/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/fabricio/.pyenv/versions/3.10.0/lib/python3.10/site-packages (from matplotlib) (3.0.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/fabricio/.pyenv/versions/3.10.0/lib/python3.10/site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/fabricio/.pyenv/versions/3.10.0/lib/python3.10/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/fabricio/.pyenv/versions/3.10.0/lib/python3.10/site-packages (from matplotlib) (9.1.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/fabricio/.pyenv/versions/3.10.0/lib/python3.10/site-packages (from matplotlib) (4.33.3)\n",
      "Requirement already satisfied: six>=1.5 in /home/fabricio/.pyenv/versions/3.10.0/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install sklearn\n",
    "!pip3 install matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import nltk\n",
    "import pickle\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import feature_extraction, linear_model, model_selection, preprocessing\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, confusion_matrix\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/fabricio/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['de', 'a', 'o', 'que', 'e', 'é', 'do', 'da', 'em', 'um', 'para', 'com', 'não', 'uma', 'os', 'no', 'se', 'na', 'por', 'mais', 'as', 'dos', 'como', 'mas', 'ao', 'ele', 'das', 'à', 'seu', 'sua', 'ou', 'quando', 'muito', 'nos', 'já', 'eu', 'também', 'só', 'pelo', 'pela', 'até', 'isso', 'ela', 'entre', 'depois', 'sem', 'mesmo', 'aos', 'seus', 'quem', 'nas', 'me', 'esse', 'eles', 'você', 'essa', 'num', 'nem', 'suas', 'meu', 'às', 'minha', 'numa', 'pelos', 'elas', 'qual', 'nós', 'lhe', 'deles', 'essas', 'esses', 'pelas', 'este', 'dele', 'tu', 'te', 'vocês', 'vos', 'lhes', 'meus', 'minhas', 'teu', 'tua', 'teus', 'tuas', 'nosso', 'nossa', 'nossos', 'nossas', 'dela', 'delas', 'esta', 'estes', 'estas', 'aquele', 'aquela', 'aqueles', 'aquelas', 'isto', 'aquilo', 'estou', 'está', 'estamos', 'estão', 'estive', 'esteve', 'estivemos', 'estiveram', 'estava', 'estávamos', 'estavam', 'estivera', 'estivéramos', 'esteja', 'estejamos', 'estejam', 'estivesse', 'estivéssemos', 'estivessem', 'estiver', 'estivermos', 'estiverem', 'hei', 'há', 'havemos', 'hão', 'houve', 'houvemos', 'houveram', 'houvera', 'houvéramos', 'haja', 'hajamos', 'hajam', 'houvesse', 'houvéssemos', 'houvessem', 'houver', 'houvermos', 'houverem', 'houverei', 'houverá', 'houveremos', 'houverão', 'houveria', 'houveríamos', 'houveriam', 'sou', 'somos', 'são', 'era', 'éramos', 'eram', 'fui', 'foi', 'fomos', 'foram', 'fora', 'fôramos', 'seja', 'sejamos', 'sejam', 'fosse', 'fôssemos', 'fossem', 'for', 'formos', 'forem', 'serei', 'será', 'seremos', 'serão', 'seria', 'seríamos', 'seriam', 'tenho', 'tem', 'temos', 'tém', 'tinha', 'tínhamos', 'tinham', 'tive', 'teve', 'tivemos', 'tiveram', 'tivera', 'tivéramos', 'tenha', 'tenhamos', 'tenham', 'tivesse', 'tivéssemos', 'tivessem', 'tiver', 'tivermos', 'tiverem', 'terei', 'terá', 'teremos', 'terão', 'teria', 'teríamos', 'teriam']\n"
     ]
    }
   ],
   "source": [
    "print(stopwords.words('portuguese'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataTRUE = \"Data/size_normalized_texts/true/\"\n",
    "\n",
    "list = os.listdir(dataTRUE)\n",
    "number_files_true = len(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFAKE = \"Data/size_normalized_texts/fake/\"\n",
    "\n",
    "list = os.listdir(dataTRUE)\n",
    "number_files_fake = len(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = []\n",
    "LABEL = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data true\n",
    "for i in range(number_files_true):\n",
    "    title = list[i]\n",
    "    LABEL.append(1)\n",
    "    with open(dataTRUE + title,'r') as reader:\n",
    "\n",
    "        doc = reader.read()\n",
    "        doc.lower()\n",
    "        doc.split()\n",
    "        reader.close\n",
    "        TEXT.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data fake\n",
    "for i in range(number_files_fake):\n",
    "    title = list[i]\n",
    "    LABEL.append(0)\n",
    "    with open(dataFAKE + title,'r') as reader:\n",
    "\n",
    "        doc = reader.read()\n",
    "        doc.lower()\n",
    "        doc.split()\n",
    "        reader.close\n",
    "        TEXT.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True 3600\n",
      "Fake 3600\n"
     ]
    }
   ],
   "source": [
    "print(f\"True {number_files_true}\")\n",
    "print(f\"Fake {number_files_fake}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(TEXT) == len(LABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label 7200 - TEXT 7200\n"
     ]
    }
   ],
   "source": [
    "print(f\"Label {len(LABEL)} - TEXT {len(TEXT)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectors_and_df(text, label):\n",
    "    \"\"\"\n",
    "    creates vectors for the text files and returns dataframe with articles as word vectors \n",
    "    \"\"\"\n",
    "    \n",
    "    cv = TfidfVectorizer()\n",
    "    cv.fit(text)\n",
    "    corpus_vecs = cv.transform(text)\n",
    "    \n",
    "    return pd.DataFrame(corpus_vecs.todense(), index=label, \n",
    "                        columns=cv.get_feature_names()), cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fabricio/.local/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Store results into dataframe, keep cv for later prediction\n",
    "df, cv = vectors_and_df(TEXT, LABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df\n",
    "y = df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.30,shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=300)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(max_iter=300)\n",
    "model.fit(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, ..., 0, 0, 1])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "pred = model.predict(Xtest)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.964484126984127\n",
      "Acuracia 0.8949074074074074\n"
     ]
    }
   ],
   "source": [
    "# Create the predictions for Y training data\n",
    "preds = model.predict(Xtest)\n",
    "\n",
    "print(model.score(Xtrain, ytrain))\n",
    "print(f\"Acuracia {model.score(Xtest, ytest)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 89.49 %\n",
      "Precision: 90.72 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\",round(metrics.accuracy_score(ytest, preds)*100, 2),'%')\n",
    "print(\"Precision:\",round(metrics.precision_score(ytest, preds)*100, 2), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[975,  98],\n",
       "       [129, 958]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix = confusion_matrix(ytest, preds)\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(new_text):\n",
    "    \n",
    "    \"\"\"\n",
    "    Takes the pre-trained model pipeline and predicts new artist based on unseen text.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model : Trained scikit-learn model pipeline.\n",
    "    new_text : str\n",
    "    \n",
    "    Returns\n",
    "    ---------\n",
    "    prediction : str\n",
    "    \n",
    "    \"\"\"\n",
    "    article = [new_text]\n",
    "    # transform song into vector matrix\n",
    "    new_article_vecs = cv.transform(article)\n",
    "    ynew = new_article_vecs.todense()\n",
    "    print(ynew.shape)\n",
    "    prediction = model.predict(ynew)\n",
    "    \n",
    "    return prediction[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = \"\"\"A Câmara aprovou nesta quarta-feira, 4, o projeto de lei que cria um piso salarial para profissionais da enfermagem, a nível nacional, que varia de R$ 2.375 a R$ 4.750. O piso deve gerar um custo de até R$ 18 bilhões aos serviços de saúde públicos e privados de acordo com o presidente da Casa, deputado Arthur Lira (PP-AL). O texto foi aprovado por 449 votos favoráveis a 12, apesar de o governo Bolsonaro ter se posicionado contra.De origem do Senado, o PL determina que o piso da categoria deverá ser reajustado anualmente com base no Índice Nacional de Preços ao Consumidor (INPC). Além disso, fica assegurada a manutenção de salários eventualmente superiores ao valor inicial sugerido, independentemente da jornada de trabalho para a qual o profissional tenha sido contratado.Contudo, de acordo com a relatora da proposta, deputada Carmen Zanotto (Cidadania-SC), o projeto só irá à sanção presidencial após promulgação da Proposta de Emenda à Constituição (PEC) 122/15, aprovada em fevereiro deste ano, que proíbe a União de criar despesas aos demais entes federativos sem prever a transferência de recursos para o custeio.Desde segunda-feira, 2, profissionais da enfermagem circulavam pela Câmara e conversavam com parlamentares, numa mobilização que levou a um amplo apoio à proposta entre deputados. No plenário, parlamentares favoráveis ao projeto argumentaram que os profissionais de saúde merecem reconhecimento por terem estado na linha de frente do combate à pandemia de covid-19.O deputado Tiago Mitraud (MG), líder do Novo, único partido contrário ao piso, afirmou que a proposta é eleitoreira e tem alto impacto orçamentário. \"Este projeto vai acabar com a saúde brasileira porque vamos ver as Santas Casas fechando, leitos de saúde fechando e os profissionais que hoje estão aqui lutando pelo piso desempregados porque os municípios não conseguirão pagar esse piso\", criticou.Na avaliação do líder do governo na Câmara, deputado Ricardo Barros (PP-PR), a criação do piso representa um grande desafio para os cofres públicos. Barros disse que, como não havia indicação da origem dos recursos para custear a proposta, a orientação do governo seria contrária. \"Neste momento, o projeto não atende à Lei de Responsabilidade Fiscal (LRF), e por isso o voto do governo é contrário\", declarou.No entanto, como a aprovação do projeto era inevitável, Barros garantiu que o governo se manterá empenhado em buscar fontes de financiamento. \"São R$ 16 bilhões que estão aguardando a fonte de recursos e nós estamos trabalhando demoradamente e insistentemente na busca de recursos para garantir que as conquistas sejam efetivas\", disse.Os profissionais beneficiados pelo projeto são enfermeiros, técnicos em enfermagem e parteiras.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT2 =  \"\"\"O ex-Secretário Nacional de Incentivo e Fomento à Cultura, André Porciúncula, revelou na manhã desta terça-feira (03) que a produtora Califórnia, da esposa de Daniela Mercury, recebeu incríveis R$ 1,8 milhões da Lei Rouanet em governos anteriores.A produtora Califórnia, da esposa da Daniela Mercury, recebeu 1,8 milhões da Rouanet dos governos antigos. Mas é claro que a Daniela está fazendo campanha para o ex-presidiário por puto amor ao Lula — escreveu Porciuncula, que também é ex-capitão da Polícia Militar da Bahia.Em outra postagem, o ex-secretário ainda revelou que o Instituto Sol da Liberdade, que pertence a cantora baiana, também recebeu 2,8 milhões da Lei Rouanet.Não é só a produtora da esposa da Daniela Mercury que lucrava milhões com a Lei Rouanet, o instituto que ela comanda costumava pegar milhões, antes do Governo Bolsonaro e as mudanças que fizemos na Rouanet. Sempre presuma uma teta vazia nos críticos do presidente — Porciuncula.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 47035)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fabricio/.local/lib/python3.8/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/fabricio/.local/lib/python3.8/site-packages/sklearn/utils/validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(TEXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# salvando modelo\n",
    "with open('classifier_news.pkl', 'wb') as files:\n",
    "    pickle.dump(model, files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load modelo\n",
    "with open('classifier_news.pkl' , 'rb') as f:\n",
    "    lr = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# salvando tfdf\n",
    "#with open('classifier_news.pkl', 'wb') as files:\n",
    "    #pickle.dump(model, files)\n",
    "    \n",
    "pickle.dump(cv, open('tfidfvect.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(model, open('model.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib_vect = pickle.load(open('tfidfvect.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = [\"adélio\",\"bispo\",\"autor\",\"facada\",\"presidente\",\"jair\",\"bolsonaro\",\"pl\",\"2018\",\"deve\",\"passar\",\"nova\",\"perícia\",\"médica\",\"próximo\",\"mês\",\"avaliar\",\"ainda\",\"representa\",\"perigo\",\"sociedade\",\"pode\",\"ser\",\"solto\",\"solicitação\",\"nova\",\"análise\",\"feita\",\"mpf\",\"ministério\",\"público\",\"federal\",\"nesta\",\"semanaquando\",\"considerado\",\"inimputável\",\"2018\",\"adélio\",\"absolvido\",\"acusações\",\"porém\",\"prevenção\",\"internado\",\"tempo\",\"indeterminado\",\"sentença\",\"fixado\",\"prazo\",\"mínimo\",\"três\",\"anos\",\"submeta\",\"nova\",\"perícia\",\"considerando\",\"decisão\",\"14\",\"abril\",\"2019\",\"partir\",\"14\",\"junho\",\"deste\",\"ano\",\"adélio\",\"pode\",\"passar\",\"nova\",\"análisepor\",\"meio\",\"nota\",\"dpu\",\"defensoria\",\"pública\",\"união\",\"ressaltou\",\"caso\",\"nova\",\"perícia\",\"conclua\",\"fim\",\"risco\",\"sociedade\",\"ainda\",\"caberá\",\"recurso\",\"eventual\",\"desinternação\",\"senhor\",\"adélio\",\"bispo\",\"somente\",\"possível\",\"partir\",\"trânsito\",\"julgado\",\"decisão\",\"determinou\",\"desinternação\",\"pondera\",\"dpu\",\"notaé\",\"importante\",\"mencionar\",\"desinternação\",\"sempre\",\"condicional\",\"devendo\",\"ser\",\"restabelecida\",\"internação\",\"agente\",\"antes\",\"decurso\",\"ano\",\"praticar\",\"fato\",\"indicativo\",\"persistência\",\"periculosidade\",\"conforme\",\"previsto\",\"art\",\"97\",\"código\",\"penal\",\"acrescentou\",\"defensorialaudo\",\"psicológico\",\"comprovou\",\"autor\",\"atentado\",\"contra\",\"hoje\",\"presidente\",\"república\",\"transtorno\",\"delirante\",\"persistente\",\"inquéritos\",\"polícia\",\"federal\",\"demonstraram\",\"agiu\",\"sozinho\",\"tentativa\",\"matar\",\"bolsonaroem\",\"carta\",\"enviada\",\"dpu\",\"revelada\",\"uol\",\"fevereiro\",\"último\",\"adélio\",\"bispo\",\"pede\",\"supremo\",\"tribunal\",\"federal\",\"stf\",\"avalie\",\"limites\",\"punição\",\"cumpre\",\"penitenciária\",\"federal\",\"campo\",\"grande\",\"ms\",\"adélio\",\"defesa\",\"deveria\",\"pedir\",\"ministros\",\"averiguem\",\"internação\",\"data\",\"acabar\",\"inconstitucionalé\",\"diz\",\"duas\",\"cartas\",\"escreveu\",\"serem\",\"entregues\",\"defensoria\",\"pública\",\"união\",\"segundo\",\"uol\",\"apurou\",\"redigidas\",\"dentro\",\"cadeia\",\"circularam\",\"mãos\",\"funcionários\",\"presídio\",\"responsável\",\"encaminhála\",\"defensor\",\"adélionuma\",\"cartas\",\"escritas\",\"mão\",\"adélio\",\"argumenta\",\"pode\",\"ficar\",\"isolado\",\"tempo\",\"prevê\",\"lei\",\"hoje\",\"detenção\",\"máxima\",\"40\",\"anosem\",\"outra\",\"carta\",\"escreveu\",\"defensoria\",\"adélio\",\"reclama\",\"quantidade\",\"medicamentos\",\"toma\",\"diz\",\"mudar\",\"tratamento\",\"médico\",\"43\",\"anos\",\"atendido\",\"médicos\",\"psiquiatras\",\"carta\",\"pede\",\"atendido\",\"psicólogos\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pkl = joblib_vect.transform(T).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fabricio/.local/lib/python3.8/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.predict(val_pkl)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(text):\n",
    "    not_punc = [char for char in text if char not in  string.punctuation]\n",
    "    not_punc = \"\".join(not_punc)\n",
    "    \n",
    "    clean_words = [word for word in not_punc.split() if word.lower() not in stopwords.words('portuguese') ]\n",
    "    return clean_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#process_text(TEXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = MultinomialNB()\n",
    "classifier.fit(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 ... 1 1 1]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(classifier.predict(Xtrain))\n",
    "print(Xtrain.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.92      0.94      2525\n",
      "           1       0.92      0.97      0.94      2515\n",
      "\n",
      "    accuracy                           0.94      5040\n",
      "   macro avg       0.94      0.94      0.94      5040\n",
      "weighted avg       0.94      0.94      0.94      5040\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predic = classifier.predict(Xtrain)\n",
    "print(classification_report(ytrain, predic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.82      0.85      1075\n",
      "           1       0.83      0.89      0.86      1085\n",
      "\n",
      "    accuracy                           0.86      2160\n",
      "   macro avg       0.86      0.86      0.86      2160\n",
      "weighted avg       0.86      0.86      0.86      2160\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predic = classifier.predict(Xtest)\n",
    "print(classification_report(ytest, predic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.96      2527\n",
      "           1       0.96      0.97      0.96      2513\n",
      "\n",
      "    accuracy                           0.96      5040\n",
      "   macro avg       0.96      0.96      0.96      5040\n",
      "weighted avg       0.96      0.96      0.96      5040\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(Xtrain)\n",
    "print(classification_report(ytrain, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.91      0.90      1073\n",
      "           1       0.91      0.88      0.89      1087\n",
      "\n",
      "    accuracy                           0.89      2160\n",
      "   macro avg       0.90      0.89      0.89      2160\n",
      "weighted avg       0.90      0.89      0.89      2160\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(Xtest)\n",
    "print(classification_report(ytest, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictNB(new_text):\n",
    "    \n",
    "    \"\"\"\n",
    "    Takes the pre-trained model pipeline and predicts new artist based on unseen text.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model : Trained scikit-learn model pipeline.\n",
    "    new_text : str\n",
    "    \n",
    "    Returns\n",
    "    ---------\n",
    "    prediction : str\n",
    "    \n",
    "    \"\"\"\n",
    "    article = [new_text]\n",
    "    # transform song into vector matrix\n",
    "    new_article_vecs = cv.transform(article)\n",
    "    ynew = new_article_vecs.todense()\n",
    "    \n",
    "    prediction = classifier.predict(ynew)\n",
    "    \n",
    "    return prediction[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fabricio/.local/lib/python3.8/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but MultinomialNB was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/fabricio/.local/lib/python3.8/site-packages/sklearn/utils/validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictNB(TEXT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_LR = LogisticRegression(max_iter=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acuracias: [0.91527778 0.88958333 0.92083333 0.91666667 0.90138889]\n",
      "acuracia final: 0.9087499999999998 +- 0.011600340565456162\n"
     ]
    }
   ],
   "source": [
    "acuracias = cross_val_score(model_LR, X, y, cv=5, scoring=\"accuracy\")\n",
    "print(\"acuracias:\", acuracias)\n",
    "print(\"acuracia final:\", np.mean(acuracias), \"+-\", np.std(acuracias))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=300)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_LR.fit(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.91527778, 0.88958333, 0.92083333, 0.91666667, 0.90138889])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9087499999999998"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acuracias.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "acuracias_classifier = cross_val_score(classifier, X, y, cv=5, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.87847222, 0.85763889, 0.86805556, 0.87569444, 0.85416667])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acuracias_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8668055555555556"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acuracias_classifier.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = TfidfVectorizer(\n",
    "            stop_words=stopwords.words('portuguese'), analyzer='word',\n",
    "            ngram_range=(1, 1), lowercase=True, use_idf=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(text):\n",
    "    \n",
    "    not_punc = [char for char in text if char not in  string.punctuation]\n",
    "    not_punc = \"\".join(not_punc)\n",
    "    \n",
    "    clean_words = [word.lower() for word in not_punc.split() if word.lower() not in stopwords.words('portuguese') ]\n",
    "    # cv.fit(clean_words)\n",
    "    # print('aqui foi ', a)\n",
    "    return clean_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictLR(new_text):\n",
    "    \n",
    "    \"\"\"\n",
    "    Takes the pre-trained model pipeline and predicts new artist based on unseen text.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model : Trained scikit-learn model pipeline.\n",
    "    new_text : str\n",
    "    \n",
    "    Returns\n",
    "    ---------\n",
    "    prediction : str\n",
    "    \n",
    "    \"\"\"\n",
    "    text = process_text(new_text)\n",
    "    new_text = [new_text]\n",
    "    print(new_text)\n",
    "    # transform song into vector matrix\n",
    "    new_article_vecs = cv.transform(text)\n",
    "    ynew = new_article_vecs.todense()\n",
    "    print(ynew)\n",
    "    prediction = lr.predict(ynew)\n",
    "    \n",
    "    return prediction[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "texto_uol = \"\"\"O presidente do Senado, Rodrigo Pacheco (PSD-MG), derrubou uma tentativa de governistas de chamar o ministro Alexandre de Moraes, do Supremo Tribunal Federal (STF), para falar sobre os inquéritos que investigam atos antidemocráticos e o uso de fake news no plenário da Casa.O senador Eduardo Girão (Pode-CE) apresentou um requerimento para a realização de uma sessão de debates temáticos com Moraes, na tentativa de pressionar o ministro. O pedido recebeu apoio de governistas, aumentando as investidas do grupo contra Moraes diante dos ataques do presidente Jair Bolsonaro ao Judiciário. Pacheco impugnou o requerimento, impedindo a realização da audiência com o ministro.De acordo com o presidente do Senado, o pedido dos governistas contraria a Constituição e os propósitos previstos no regimento do Senado para a realização de debates temáticos, abrindo caminho para um \"controle indireto de atos jurisdicionais\" por meio de uma sessão com o magistrado. Girão recorreu da decisão de Pacheco. O presidente da Casa não julgou o recurso.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = TfidfVectorizer(\n",
    "            stop_words=stopwords.words('portuguese'), analyzer='word',\n",
    "            ngram_range=(1, 1), lowercase=True,binary=True, use_idf=True)\n",
    "\n",
    "\n",
    "\n",
    "#texto_uol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(binary=True,\n",
       "                stop_words=['de', 'a', 'o', 'que', 'e', 'é', 'do', 'da', 'em',\n",
       "                            'um', 'para', 'com', 'não', 'uma', 'os', 'no', 'se',\n",
       "                            'na', 'por', 'mais', 'as', 'dos', 'como', 'mas',\n",
       "                            'ao', 'ele', 'das', 'à', 'seu', 'sua', ...])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.fit(texto_uol.split(','))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fabricio/.local/lib/python3.8/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/fabricio/.local/lib/python3.8/site-packages/sklearn/utils/validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(texto_uol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 72)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_vecs = tf.transform(texto_uol.split(','))\n",
    "\n",
    "ynew = corpus_vecs.todense()\n",
    "#lr.predict()\n",
    "ynew.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O presidente do Senado, Rodrigo Pacheco (PSD-MG), derrubou uma tentativa de governistas de chamar o ministro Alexandre de Moraes, do Supremo Tribunal Federal (STF), para falar sobre os inquéritos que investigam atos antidemocráticos e o uso de fake news no plenário da Casa.O senador Eduardo Girão (Pode-CE) apresentou um requerimento para a realização de uma sessão de debates temáticos com Moraes, na tentativa de pressionar o ministro. O pedido recebeu apoio de governistas, aumentando as investidas do grupo contra Moraes diante dos ataques do presidente Jair Bolsonaro ao Judiciário. Pacheco impugnou o requerimento, impedindo a realização da audiência com o ministro.De acordo com o presidente do Senado, o pedido dos governistas contraria a Constituição e os propósitos previstos no regimento do Senado para a realização de debates temáticos, abrindo caminho para um \"controle indireto de atos jurisdicionais\" por meio de uma sessão com o magistrado. Girão recorreu da decisão de Pacheco. O presidente da Casa não julgou o recurso.']\n"
     ]
    },
    {
     "ename": "NotFittedError",
     "evalue": "The TF-IDF vectorizer is not fitted",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_11447/1793871712.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredictLR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexto_uol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_11447/2604597521.py\u001b[0m in \u001b[0;36mpredictLR\u001b[0;34m(new_text)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# transform song into vector matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mnew_article_vecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mynew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_article_vecs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtodense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mynew\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, raw_documents)\u001b[0m\n\u001b[1;32m   2097\u001b[0m             \u001b[0mTf\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0midf\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mweighted\u001b[0m \u001b[0mdocument\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mterm\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2098\u001b[0m         \"\"\"\n\u001b[0;32m-> 2099\u001b[0;31m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"The TF-IDF vectorizer is not fitted\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2101\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_is_fitted\u001b[0;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[1;32m   1220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfitted\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1222\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"name\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFittedError\u001b[0m: The TF-IDF vectorizer is not fitted"
     ]
    }
   ],
   "source": [
    "predictLR(texto_uol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('classifier_news.pkl' , 'rb') as f:\n",
    "    classifier_news = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(text):\n",
    "    not_punc = [char for char in text if char not in  string.punctuation]\n",
    "    not_punc = \"\".join(not_punc)\n",
    "    \n",
    "    clean_words = [word for word in not_punc.split() if word.lower() not in stopwords.words('portuguese') ]\n",
    "    return clean_words\n",
    "\n",
    "\n",
    "def vectorized_text(text):\n",
    "    cv = TfidfVectorizer(strip_accents=None, lowercase=False, preprocessor=None, use_idf=True, norm='l2', smooth_idf=True)\n",
    "    cv.fit(text)\n",
    "    corpus_vecs = cv.fit_transform(text)\n",
    "    ynew = corpus_vecs.todense()\n",
    "    return ynew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TXT = \"\"\"O ex-governador de São Paulo Geraldo Alckmin (PSB) testou positivo para covid-19, um dia antes do lançamento da chapa do ex-presidente Luiz Inácio Lula da Silva (PT) ao Palácio do Planalto. O UOL confirmou a informação com a pré-campanha de Lula.Segundo o deputado José Guimarães (PT-CE), Alckmin avisou à cúpula petista do diagnóstico, mas o comitê de campanha decidiu manter o ato político no sábado (7), em São Paulo, e o ex-governador deve participar de forma virtual.Por meio de nota, a assessoria de comunicação do ex-governador de São Paulo, que foi vacinado contra a covid-19 com as três doses, disse que ele está em casa e passa bem. A assessoria também confirmou que o evento está mantido e ele pode participar de forma remota.A previsão é de que o evento de pré-candidatura reúna 4.000 convidados, entre políticos em geral, pré-candidatos nos estados, artistas, empresários, sindicalistas e representantes da sociedade civil. O lançamento acontecerá no Expo Center Norte, às 10h deste sábado.Sete partidos se aliarão oficialmente: PT, PSB, PC do B, PSOL, Rede, PV e Solidariedade. Representantes de outros partidos, como PSD, Avante e MDB, também foram convidados para o ato de sábado.Alckmin esteve com Lula e vários outros petistas na segunda-feira (2) em reuniões de avaliação. Dois dias depois, ele se reuniu com o ex-ministro Aloizio Mercadante para discutir o programa de governo de sua chapa com Lula. O encontro ocorreu na Fundação Perseu Abramo, em São Paulo.Na reunião, Mercadante pediu indicações de nomes técnicos para debater o programa de governo e sugestões ao ex-governador, que defendeu a necessidade de se construir um \"pacto republicano\" no Brasil. Alckmin falou também do agronegócio. Parte do setor rejeita Lula e prefere o presidente Jair Bolsonaro (PL), mas o ex-governador tem tentado reduzir essa resistência ao petista no setor rural.Na próxima semana, estava prevista uma viagem de Alckmin a Minas Gerais, com Lula, mas o ex-governador também não poderá participar.*Com Estadão Conteúdo e Reuters\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_text = process_text(TEXT)\n",
    "vector_text = vectorized_text(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=300)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fabricio/.local/lib/python3.8/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/fabricio/.local/lib/python3.8/site-packages/sklearn/utils/validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 206 features, but LogisticRegression is expecting 47035 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_475283/3352738226.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier_news\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvector_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    423\u001b[0m             \u001b[0mVector\u001b[0m \u001b[0mcontaining\u001b[0m \u001b[0mthe\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0meach\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m         \"\"\"\n\u001b[0;32m--> 425\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    405\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdense_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintercept_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ensure_2d\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 585\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_n_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_features_in_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    401\u001b[0m                 \u001b[0;34mf\"X has {n_features} features, but {self.__class__.__name__} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m                 \u001b[0;34mf\"is expecting {self.n_features_in_} features as input.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: X has 206 features, but LogisticRegression is expecting 47035 features as input."
     ]
    }
   ],
   "source": [
    "prediction = classifier_news.predict(vector_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictNB(new_text):\n",
    "    \n",
    "    \"\"\"\n",
    "    Takes the pre-trained model pipeline and predicts new artist based on unseen text.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model : Trained scikit-learn model pipeline.\n",
    "    new_text : str\n",
    "    \n",
    "    Returns\n",
    "    ---------\n",
    "    prediction : str\n",
    "    \n",
    "    \"\"\"\n",
    "    new_text = process_text(new_text)\n",
    "    print(len(new_text))\n",
    "    cv = TfidfVectorizer()\n",
    "    cv.fit(new_text)\n",
    "    # transform song into vector matrix\n",
    "\n",
    "    new_article_vecs = cv.transform(new_text)\n",
    "    ynew = new_article_vecs.todense()\n",
    "    \n",
    "    f = np.transpose(ynew)\n",
    "    print(f)\n",
    "    \n",
    "    prediction = model.predict(ynew)\n",
    "        \n",
    "    return prediction[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fabricio/.local/lib/python3.8/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/fabricio/.local/lib/python3.8/site-packages/sklearn/utils/validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 153 features, but LogisticRegression is expecting 47035 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_475283/2935573043.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredictNB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTXT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_475283/3655765303.py\u001b[0m in \u001b[0;36mpredictNB\u001b[0;34m(new_text)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mynew\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    423\u001b[0m             \u001b[0mVector\u001b[0m \u001b[0mcontaining\u001b[0m \u001b[0mthe\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0meach\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m         \"\"\"\n\u001b[0;32m--> 425\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    405\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdense_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintercept_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ensure_2d\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 585\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_n_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_features_in_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    401\u001b[0m                 \u001b[0;34mf\"X has {n_features} features, but {self.__class__.__name__} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m                 \u001b[0;34mf\"is expecting {self.n_features_in_} features as input.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: X has 153 features, but LogisticRegression is expecting 47035 features as input."
     ]
    }
   ],
   "source": [
    "predictNB(TXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dddd26fa142b3dd5cbd75e1307ca13babd1ce0a9a1b45eca79ff918f7acc4b76"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit ('3.10.0')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
