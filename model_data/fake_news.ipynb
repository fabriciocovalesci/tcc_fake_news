{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn in /home/fabricio/.pyenv/versions/3.10.0/lib/python3.10/site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in /home/fabricio/.pyenv/versions/3.10.0/lib/python3.10/site-packages (from sklearn) (1.0.2)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/fabricio/.pyenv/versions/3.10.0/lib/python3.10/site-packages (from scikit-learn->sklearn) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/fabricio/.pyenv/versions/3.10.0/lib/python3.10/site-packages (from scikit-learn->sklearn) (3.1.0)\n",
      "Requirement already satisfied: numpy>=1.14.6 in /home/fabricio/.pyenv/versions/3.10.0/lib/python3.10/site-packages (from scikit-learn->sklearn) (1.22.3)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /home/fabricio/.pyenv/versions/3.10.0/lib/python3.10/site-packages (from scikit-learn->sklearn) (1.8.0)\n",
      "Requirement already satisfied: matplotlib in /home/fabricio/.pyenv/versions/3.10.0/lib/python3.10/site-packages (3.5.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/fabricio/.pyenv/versions/3.10.0/lib/python3.10/site-packages (from matplotlib) (1.4.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/fabricio/.pyenv/versions/3.10.0/lib/python3.10/site-packages (from matplotlib) (1.22.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/fabricio/.pyenv/versions/3.10.0/lib/python3.10/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/fabricio/.pyenv/versions/3.10.0/lib/python3.10/site-packages (from matplotlib) (3.0.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/fabricio/.pyenv/versions/3.10.0/lib/python3.10/site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/fabricio/.pyenv/versions/3.10.0/lib/python3.10/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/fabricio/.pyenv/versions/3.10.0/lib/python3.10/site-packages (from matplotlib) (9.1.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/fabricio/.pyenv/versions/3.10.0/lib/python3.10/site-packages (from matplotlib) (4.33.3)\n",
      "Requirement already satisfied: six>=1.5 in /home/fabricio/.pyenv/versions/3.10.0/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install sklearn\n",
    "!pip3 install matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import nltk\n",
    "import pickle\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import feature_extraction, linear_model, model_selection, preprocessing\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, confusion_matrix\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/fabricio/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['de', 'a', 'o', 'que', 'e', 'é', 'do', 'da', 'em', 'um', 'para', 'com', 'não', 'uma', 'os', 'no', 'se', 'na', 'por', 'mais', 'as', 'dos', 'como', 'mas', 'ao', 'ele', 'das', 'à', 'seu', 'sua', 'ou', 'quando', 'muito', 'nos', 'já', 'eu', 'também', 'só', 'pelo', 'pela', 'até', 'isso', 'ela', 'entre', 'depois', 'sem', 'mesmo', 'aos', 'seus', 'quem', 'nas', 'me', 'esse', 'eles', 'você', 'essa', 'num', 'nem', 'suas', 'meu', 'às', 'minha', 'numa', 'pelos', 'elas', 'qual', 'nós', 'lhe', 'deles', 'essas', 'esses', 'pelas', 'este', 'dele', 'tu', 'te', 'vocês', 'vos', 'lhes', 'meus', 'minhas', 'teu', 'tua', 'teus', 'tuas', 'nosso', 'nossa', 'nossos', 'nossas', 'dela', 'delas', 'esta', 'estes', 'estas', 'aquele', 'aquela', 'aqueles', 'aquelas', 'isto', 'aquilo', 'estou', 'está', 'estamos', 'estão', 'estive', 'esteve', 'estivemos', 'estiveram', 'estava', 'estávamos', 'estavam', 'estivera', 'estivéramos', 'esteja', 'estejamos', 'estejam', 'estivesse', 'estivéssemos', 'estivessem', 'estiver', 'estivermos', 'estiverem', 'hei', 'há', 'havemos', 'hão', 'houve', 'houvemos', 'houveram', 'houvera', 'houvéramos', 'haja', 'hajamos', 'hajam', 'houvesse', 'houvéssemos', 'houvessem', 'houver', 'houvermos', 'houverem', 'houverei', 'houverá', 'houveremos', 'houverão', 'houveria', 'houveríamos', 'houveriam', 'sou', 'somos', 'são', 'era', 'éramos', 'eram', 'fui', 'foi', 'fomos', 'foram', 'fora', 'fôramos', 'seja', 'sejamos', 'sejam', 'fosse', 'fôssemos', 'fossem', 'for', 'formos', 'forem', 'serei', 'será', 'seremos', 'serão', 'seria', 'seríamos', 'seriam', 'tenho', 'tem', 'temos', 'tém', 'tinha', 'tínhamos', 'tinham', 'tive', 'teve', 'tivemos', 'tiveram', 'tivera', 'tivéramos', 'tenha', 'tenhamos', 'tenham', 'tivesse', 'tivéssemos', 'tivessem', 'tiver', 'tivermos', 'tiverem', 'terei', 'terá', 'teremos', 'terão', 'teria', 'teríamos', 'teriam']\n"
     ]
    }
   ],
   "source": [
    "print(stopwords.words('portuguese'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataTRUE = \"Data/size_normalized_texts/true/\"\n",
    "\n",
    "list = os.listdir(dataTRUE)\n",
    "number_files_true = len(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFAKE = \"Data/size_normalized_texts/fake/\"\n",
    "\n",
    "list = os.listdir(dataTRUE)\n",
    "number_files_fake = len(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = []\n",
    "LABEL = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data true\n",
    "for i in range(number_files_true):\n",
    "    title = list[i]\n",
    "    LABEL.append(1)\n",
    "    with open(dataTRUE + title,'r') as reader:\n",
    "\n",
    "        doc = reader.read()\n",
    "        doc.lower()\n",
    "        doc.split()\n",
    "        reader.close\n",
    "        TEXT.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data fake\n",
    "for i in range(number_files_fake):\n",
    "    title = list[i]\n",
    "    LABEL.append(0)\n",
    "    with open(dataFAKE + title,'r') as reader:\n",
    "\n",
    "        doc = reader.read()\n",
    "        doc.lower()\n",
    "        doc.split()\n",
    "        reader.close\n",
    "        TEXT.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True 3600\n",
      "Fake 3600\n"
     ]
    }
   ],
   "source": [
    "print(f\"True {number_files_true}\")\n",
    "print(f\"Fake {number_files_fake}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(TEXT) == len(LABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label 7200 - TEXT 7200\n"
     ]
    }
   ],
   "source": [
    "print(f\"Label {len(LABEL)} - TEXT {len(TEXT)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectors_and_df(text, label):\n",
    "    \"\"\"\n",
    "    creates vectors for the text files and returns dataframe with articles as word vectors \n",
    "    \"\"\"\n",
    "    \n",
    "    cv = TfidfVectorizer()\n",
    "    cv.fit(text)\n",
    "    corpus_vecs = cv.transform(text)\n",
    "    \n",
    "    return pd.DataFrame(corpus_vecs.todense(), index=label, \n",
    "                        columns=cv.get_feature_names()), cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fabricio/.local/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Store results into dataframe, keep cv for later prediction\n",
    "df, cv = vectors_and_df(TEXT, LABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df\n",
    "y = df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.30,shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=300)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(max_iter=300)\n",
    "model.fit(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, ..., 0, 0, 1])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "pred = model.predict(Xtest)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.964484126984127\n",
      "Acuracia 0.8949074074074074\n"
     ]
    }
   ],
   "source": [
    "# Create the predictions for Y training data\n",
    "preds = model.predict(Xtest)\n",
    "\n",
    "print(model.score(Xtrain, ytrain))\n",
    "print(f\"Acuracia {model.score(Xtest, ytest)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 89.49 %\n",
      "Precision: 90.72 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\",round(metrics.accuracy_score(ytest, preds)*100, 2),'%')\n",
    "print(\"Precision:\",round(metrics.precision_score(ytest, preds)*100, 2), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[975,  98],\n",
       "       [129, 958]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix = confusion_matrix(ytest, preds)\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(new_text):\n",
    "    \n",
    "    \"\"\"\n",
    "    Takes the pre-trained model pipeline and predicts new artist based on unseen text.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model : Trained scikit-learn model pipeline.\n",
    "    new_text : str\n",
    "    \n",
    "    Returns\n",
    "    ---------\n",
    "    prediction : str\n",
    "    \n",
    "    \"\"\"\n",
    "    article = [new_text]\n",
    "    # transform song into vector matrix\n",
    "    new_article_vecs = cv.transform(article)\n",
    "    ynew = new_article_vecs.todense()\n",
    "    \n",
    "    prediction = model.predict(ynew)\n",
    "    \n",
    "    return prediction[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = \"\"\"A Câmara aprovou nesta quarta-feira, 4, o projeto de lei que cria um piso salarial para profissionais da enfermagem, a nível nacional, que varia de R$ 2.375 a R$ 4.750. O piso deve gerar um custo de até R$ 18 bilhões aos serviços de saúde públicos e privados de acordo com o presidente da Casa, deputado Arthur Lira (PP-AL). O texto foi aprovado por 449 votos favoráveis a 12, apesar de o governo Bolsonaro ter se posicionado contra.De origem do Senado, o PL determina que o piso da categoria deverá ser reajustado anualmente com base no Índice Nacional de Preços ao Consumidor (INPC). Além disso, fica assegurada a manutenção de salários eventualmente superiores ao valor inicial sugerido, independentemente da jornada de trabalho para a qual o profissional tenha sido contratado.Contudo, de acordo com a relatora da proposta, deputada Carmen Zanotto (Cidadania-SC), o projeto só irá à sanção presidencial após promulgação da Proposta de Emenda à Constituição (PEC) 122/15, aprovada em fevereiro deste ano, que proíbe a União de criar despesas aos demais entes federativos sem prever a transferência de recursos para o custeio.Desde segunda-feira, 2, profissionais da enfermagem circulavam pela Câmara e conversavam com parlamentares, numa mobilização que levou a um amplo apoio à proposta entre deputados. No plenário, parlamentares favoráveis ao projeto argumentaram que os profissionais de saúde merecem reconhecimento por terem estado na linha de frente do combate à pandemia de covid-19.O deputado Tiago Mitraud (MG), líder do Novo, único partido contrário ao piso, afirmou que a proposta é eleitoreira e tem alto impacto orçamentário. \"Este projeto vai acabar com a saúde brasileira porque vamos ver as Santas Casas fechando, leitos de saúde fechando e os profissionais que hoje estão aqui lutando pelo piso desempregados porque os municípios não conseguirão pagar esse piso\", criticou.Na avaliação do líder do governo na Câmara, deputado Ricardo Barros (PP-PR), a criação do piso representa um grande desafio para os cofres públicos. Barros disse que, como não havia indicação da origem dos recursos para custear a proposta, a orientação do governo seria contrária. \"Neste momento, o projeto não atende à Lei de Responsabilidade Fiscal (LRF), e por isso o voto do governo é contrário\", declarou.No entanto, como a aprovação do projeto era inevitável, Barros garantiu que o governo se manterá empenhado em buscar fontes de financiamento. \"São R$ 16 bilhões que estão aguardando a fonte de recursos e nós estamos trabalhando demoradamente e insistentemente na busca de recursos para garantir que as conquistas sejam efetivas\", disse.Os profissionais beneficiados pelo projeto são enfermeiros, técnicos em enfermagem e parteiras.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT2 =  \"\"\"O ex-Secretário Nacional de Incentivo e Fomento à Cultura, André Porciúncula, revelou na manhã desta terça-feira (03) que a produtora Califórnia, da esposa de Daniela Mercury, recebeu incríveis R$ 1,8 milhões da Lei Rouanet em governos anteriores.A produtora Califórnia, da esposa da Daniela Mercury, recebeu 1,8 milhões da Rouanet dos governos antigos. Mas é claro que a Daniela está fazendo campanha para o ex-presidiário por puto amor ao Lula — escreveu Porciuncula, que também é ex-capitão da Polícia Militar da Bahia.Em outra postagem, o ex-secretário ainda revelou que o Instituto Sol da Liberdade, que pertence a cantora baiana, também recebeu 2,8 milhões da Lei Rouanet.Não é só a produtora da esposa da Daniela Mercury que lucrava milhões com a Lei Rouanet, o instituto que ela comanda costumava pegar milhões, antes do Governo Bolsonaro e as mudanças que fizemos na Rouanet. Sempre presuma uma teta vazia nos críticos do presidente — Porciuncula.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fabricio/.local/lib/python3.8/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/fabricio/.local/lib/python3.8/site-packages/sklearn/utils/validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(TEXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# salvando modelo\n",
    "with open('classifier_news', 'wb') as files:\n",
    "    pickle.dump(model, files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load modelo\n",
    "with open('classifier_news' , 'rb') as f:\n",
    "    lr = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, ..., 0, 0, 1])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.predict(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(text):\n",
    "    not_punc = [char for char in text if char not in  string.punctuation]\n",
    "    not_punc = \"\".join(not_punc)\n",
    "    \n",
    "    clean_words = [word for word in not_punc.split() if word.lower() not in stopwords.words('portuguese') ]\n",
    "    return clean_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#process_text(TEXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = MultinomialNB()\n",
    "classifier.fit(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 ... 1 1 1]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(classifier.predict(Xtrain))\n",
    "print(Xtrain.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.92      0.94      2525\n",
      "           1       0.92      0.97      0.94      2515\n",
      "\n",
      "    accuracy                           0.94      5040\n",
      "   macro avg       0.94      0.94      0.94      5040\n",
      "weighted avg       0.94      0.94      0.94      5040\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predic = classifier.predict(Xtrain)\n",
    "print(classification_report(ytrain, predic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.82      0.85      1075\n",
      "           1       0.83      0.89      0.86      1085\n",
      "\n",
      "    accuracy                           0.86      2160\n",
      "   macro avg       0.86      0.86      0.86      2160\n",
      "weighted avg       0.86      0.86      0.86      2160\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predic = classifier.predict(Xtest)\n",
    "print(classification_report(ytest, predic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.96      2527\n",
      "           1       0.96      0.97      0.96      2513\n",
      "\n",
      "    accuracy                           0.96      5040\n",
      "   macro avg       0.96      0.96      0.96      5040\n",
      "weighted avg       0.96      0.96      0.96      5040\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(Xtrain)\n",
    "print(classification_report(ytrain, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.91      0.90      1073\n",
      "           1       0.91      0.88      0.89      1087\n",
      "\n",
      "    accuracy                           0.89      2160\n",
      "   macro avg       0.90      0.89      0.89      2160\n",
      "weighted avg       0.90      0.89      0.89      2160\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(Xtest)\n",
    "print(classification_report(ytest, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictNB(new_text):\n",
    "    \n",
    "    \"\"\"\n",
    "    Takes the pre-trained model pipeline and predicts new artist based on unseen text.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model : Trained scikit-learn model pipeline.\n",
    "    new_text : str\n",
    "    \n",
    "    Returns\n",
    "    ---------\n",
    "    prediction : str\n",
    "    \n",
    "    \"\"\"\n",
    "    article = [new_text]\n",
    "    # transform song into vector matrix\n",
    "    new_article_vecs = cv.transform(article)\n",
    "    ynew = new_article_vecs.todense()\n",
    "    \n",
    "    prediction = classifier.predict(ynew)\n",
    "    \n",
    "    return prediction[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fabricio/.local/lib/python3.8/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but MultinomialNB was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/fabricio/.local/lib/python3.8/site-packages/sklearn/utils/validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictNB(TEXT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_LR = LogisticRegression(max_iter=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acuracias: [0.91527778 0.88958333 0.92083333 0.91666667 0.90138889]\n",
      "acuracia final: 0.9087499999999998 +- 0.011600340565456162\n"
     ]
    }
   ],
   "source": [
    "acuracias = cross_val_score(model_LR, X, y, cv=5, scoring=\"accuracy\")\n",
    "print(\"acuracias:\", acuracias)\n",
    "print(\"acuracia final:\", np.mean(acuracias), \"+-\", np.std(acuracias))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=300)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_LR.fit(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.91527778, 0.88958333, 0.92083333, 0.91666667, 0.90138889])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9087499999999998"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acuracias.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "acuracias_classifier = cross_val_score(classifier, X, y, cv=5, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.87847222, 0.85763889, 0.86805556, 0.87569444, 0.85416667])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acuracias_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8668055555555556"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acuracias_classifier.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictNB(new_text):\n",
    "    \n",
    "    \"\"\"\n",
    "    Takes the pre-trained model pipeline and predicts new artist based on unseen text.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model : Trained scikit-learn model pipeline.\n",
    "    new_text : str\n",
    "    \n",
    "    Returns\n",
    "    ---------\n",
    "    prediction : str\n",
    "    \n",
    "    \"\"\"\n",
    "    article = [new_text]\n",
    "    # transform song into vector matrix\n",
    "    new_article_vecs = cv.transform(article)\n",
    "    ynew = new_article_vecs.todense()\n",
    "    \n",
    "    prediction = model_LR.predict(ynew)\n",
    "    \n",
    "    return prediction[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "texto_uol = \"\"\"O presidente do Senado, Rodrigo Pacheco (PSD-MG), derrubou uma tentativa de governistas de chamar o ministro Alexandre de Moraes, do Supremo Tribunal Federal (STF), para falar sobre os inquéritos que investigam atos antidemocráticos e o uso de fake news no plenário da Casa.O senador Eduardo Girão (Pode-CE) apresentou um requerimento para a realização de uma sessão de debates temáticos com Moraes, na tentativa de pressionar o ministro. O pedido recebeu apoio de governistas, aumentando as investidas do grupo contra Moraes diante dos ataques do presidente Jair Bolsonaro ao Judiciário. Pacheco impugnou o requerimento, impedindo a realização da audiência com o ministro.De acordo com o presidente do Senado, o pedido dos governistas contraria a Constituição e os propósitos previstos no regimento do Senado para a realização de debates temáticos, abrindo caminho para um \"controle indireto de atos jurisdicionais\" por meio de uma sessão com o magistrado. Girão recorreu da decisão de Pacheco. O presidente da Casa não julgou o recurso.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fabricio/.local/lib/python3.8/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/fabricio/.local/lib/python3.8/site-packages/sklearn/utils/validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictNB(texto_uol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
